"""
å¢å¼ºç‰ˆ Twitter çˆ¬è™«å‡½æ•°
å¯ä»¥ç›´æ¥æ›¿æ¢ collect.py ä¸­çš„ fetch_twitter å‡½æ•°ä½¿ç”¨

æ”¹è¿›ç‚¹:
1. æ›´å¤š Nitter å®ä¾‹
2. æ›´å¥å£®çš„ HTML è§£æ
3. æ›´å¥½çš„é”™è¯¯å¤„ç†
4. æ”¯æŒå¤šç§ HTML ç»“æ„
"""

import requests
from bs4 import BeautifulSoup
import time

def fetch_twitter_enhanced(keyword, limit=30):
    """å¢å¼ºç‰ˆ Nitter çˆ¬è™« - æ›´å¥å£®çš„å®ç°"""
    
    # æ›´å…¨é¢çš„ Nitter å®ä¾‹åˆ—è¡¨ï¼ˆå®šæœŸæ›´æ–°ï¼‰
    instances = [
        "nitter.poast.org",
        "nitter.privacyredirect.com", 
        "nitter.tiekoetter.com",
        "nitter.net",
        "nitter.unixfox.eu",
        "nitter.kavin.rocks",
        "nitter.fdn.fr",
        "nitter.1d4.us",
        "nitter.hu",
        "nitter.cz"
    ]
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1"
    }
    
    tweets = []
    successful_instance = None
    
    for instance in instances:
        if len(tweets) >= limit:
            break
            
        url = f"https://{instance}/search"
        params = {"q": keyword, "f": "tweets"}  # f=tweets åªæ˜¾ç¤ºæ¨æ–‡
        
        try:
            print(f"   ğŸ” å°è¯•ä» {instance} æŠ“å–...")
            resp = requests.get(url, headers=headers, params=params, timeout=20)
            
            if resp.status_code != 200:
                print(f"   âš ï¸ {instance} è¿”å›çŠ¶æ€ç  {resp.status_code}")
                continue
                
            soup = BeautifulSoup(resp.text, "html.parser")
            
            # å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨ï¼ˆä¸åŒçš„ Nitter å®ä¾‹å¯èƒ½ HTML ç»“æ„ç•¥æœ‰ä¸åŒï¼‰
            items = soup.select(".timeline-item")
            if not items:
                items = soup.select("div.timeline-item")
            if not items:
                print(f"   âš ï¸ {instance} æœªæ‰¾åˆ°æ¨æ–‡å®¹å™¨")
                continue
            
            print(f"   ğŸ“ æ‰¾åˆ° {len(items)} ä¸ªæ—¶é—´çº¿é¡¹ç›®")
            
            for item in items:
                if len(tweets) >= limit:
                    break
                    
                # æ’é™¤éæ¨æ–‡é¡¹ï¼ˆå¦‚"åŠ è½½æ›´å¤š"ï¼‰
                item_classes = item.get("class", [])
                if "show-more" in item_classes or "timeline-protected" in item_classes:
                    continue
                
                try:
                    # æ–¹æ³•1: é€šè¿‡ .tweet-link è·å–é“¾æ¥
                    tweet_link_el = item.select_one(".tweet-link")
                    if not tweet_link_el:
                        # æ–¹æ³•2: é€šè¿‡ .tweet-date a è·å–é“¾æ¥
                        tweet_link_el = item.select_one(".tweet-date a")
                    
                    if not tweet_link_el:
                        continue
                    
                    tweet_path = tweet_link_el.get("href", "")
                    if not tweet_path or "/status/" not in tweet_path:
                        continue
                    
                    # æå–æ¨æ–‡ IDï¼ˆæ›´å¥å£®çš„æ–¹å¼ï¼‰
                    try:
                        # tweet_path æ ¼å¼: /username/status/123456789#m
                        parts = tweet_path.split("/")
                        status_index = parts.index("status") if "status" in parts else -1
                        if status_index > 0 and status_index + 1 < len(parts):
                            tweet_id = parts[status_index + 1].split("#")[0].split("?")[0]
                            username_from_path = parts[status_index - 1] if status_index > 0 else ""
                        else:
                            continue
                    except:
                        continue
                    
                    # æå–ç”¨æˆ·åï¼ˆå¤šç§æ–¹å¼ï¼‰
                    username_el = item.select_one(".username")
                    if not username_el:
                        username_el = item.select_one(".fullname + a")
                    username = username_el.get_text(strip=True).lstrip("@") if username_el else username_from_path
                    
                    # æå–æ¨æ–‡å†…å®¹
                    content_el = item.select_one(".tweet-content")
                    if not content_el:
                        content_el = item.select_one("div.tweet-content")
                    content = content_el.get_text(separator=" ", strip=True) if content_el else ""
                    
                    # å¦‚æœå†…å®¹ä¸ºç©º,è·³è¿‡
                    if not content:
                        continue
                    
                    # æå–æ—¶é—´
                    date_el = item.select_one(".tweet-date a")
                    created_at = ""
                    if date_el:
                        created_at = date_el.get("title", "")
                        if not created_at:
                            created_at = date_el.get_text(strip=True)
                    
                    # æå–ç»Ÿè®¡æ•°æ®ï¼ˆæ›´å¥å£®çš„è§£æï¼‰
                    retweet_count = 0
                    like_count = 0
                    
                    # å°è¯•ä» .tweet-stats æå–
                    stats_container = item.select_one(".tweet-stats")
                    if stats_container:
                        # æŸ¥æ‰¾è½¬å‘æ•°
                        retweet_el = stats_container.select_one(".icon-retweet")
                        if retweet_el:
                            parent = retweet_el.find_parent("div", class_="icon-container")
                            if parent:
                                text = parent.get_text(strip=True).replace(",", "")
                                try:
                                    retweet_count = int(text) if text.isdigit() else 0
                                except:
                                    pass
                        
                        # æŸ¥æ‰¾ç‚¹èµæ•°
                        like_el = stats_container.select_one(".icon-heart")
                        if like_el:
                            parent = like_el.find_parent("div", class_="icon-container")
                            if parent:
                                text = parent.get_text(strip=True).replace(",", "")
                                try:
                                    like_count = int(text) if text.isdigit() else 0
                                except:
                                    pass
                    
                    # é¿å…é‡å¤
                    if any(t["tweet_id"] == tweet_id for t in tweets):
                        continue
                    
                    tweets.append({
                        "tweet_id": tweet_id,
                        "content": content,
                        "username": username,
                        "created_at": created_at,
                        "retweet_count": retweet_count,
                        "like_count": like_count,
                        "url": f"https://twitter.com/{username}/status/{tweet_id}"
                    })
                    
                except Exception as e:
                    # è°ƒè¯•æ—¶å¯ä»¥å–æ¶ˆæ³¨é‡ŠæŸ¥çœ‹å…·ä½“é”™è¯¯
                    # print(f"   âŒ è§£æå•æ¡æ¨æ–‡å¤±è´¥: {e}")
                    # import traceback; traceback.print_exc()
                    continue
                    
            if tweets:
                successful_instance = instance
                print(f"   âœ… ä» {instance} æˆåŠŸè·å– {len(tweets)} æ¡æ¨æ–‡")
                break  # å¦‚æœæŠ“å–åˆ°äº†ï¼Œå°±æš‚æ—¶ä¸å°è¯•å…¶ä»–å®ä¾‹
            else:
                print(f"   âš ï¸ {instance} æœªèƒ½è§£æå‡ºæœ‰æ•ˆæ¨æ–‡")
                
        except requests.exceptions.Timeout:
            print(f"   âŒ {instance} è¯·æ±‚è¶…æ—¶")
            continue
        except requests.exceptions.ConnectionError:
            print(f"   âŒ {instance} è¿æ¥å¤±è´¥")
            continue
        except Exception as e:
            print(f"   âŒ è®¿é—® {instance} å‡ºé”™: {e}")
            continue
    
    if not tweets:
        print(f"   âš ï¸  æ‰€æœ‰ Nitter å®ä¾‹å‡å¤±è´¥")
        print(f"   ğŸ’¡ å»ºè®®æ–¹æ¡ˆ:")
        print(f"      1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print(f"      2. è®¿é—® https://github.com/zedeus/nitter/wiki/Instances è·å–æœ€æ–°å®ä¾‹åˆ—è¡¨")
        print(f"      3. ä½¿ç”¨ twitter_scraper_selenium.py (æ— å¤´æµè§ˆå™¨æ–¹æ¡ˆ)")
        print(f"      4. è€ƒè™‘ä½¿ç”¨ä»˜è´¹ Twitter API")
    
    return tweets


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("æµ‹è¯•å¢å¼ºç‰ˆ Twitter çˆ¬è™«...")
    tweets = fetch_twitter_enhanced("DeepSeek", limit=10)
    
    print(f"\næ€»å…±è·å– {len(tweets)} æ¡æ¨æ–‡\n")
    
    if tweets:
        print("å‰ 5 æ¡æ¨æ–‡é¢„è§ˆ:")
        print("=" * 80)
        for i, tweet in enumerate(tweets[:5], 1):
            print(f"\n{i}. @{tweet['username']}")
            print(f"   å†…å®¹: {tweet['content'][:150]}...")
            print(f"   æ—¶é—´: {tweet['created_at']}")
            print(f"   äº’åŠ¨: â¤ï¸ {tweet['like_count']} | ğŸ” {tweet['retweet_count']}")
            print(f"   é“¾æ¥: {tweet['url']}")
        print("\n" + "=" * 80)
    else:
        print("âŒ æœªèƒ½è·å–ä»»ä½•æ¨æ–‡ï¼Œè¯·å°è¯• Selenium æ–¹æ¡ˆ")
